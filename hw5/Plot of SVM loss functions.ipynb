{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%matplotlib nbagg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Hinge loss is Lh = max(0, 1-yt)\n",
    "\n",
    "samples = np.linspace(-3, 3, 1000)\n",
    "classification_point = 0;\n",
    "h = 0.45\n",
    "\n",
    "actual_classification = np.where(samples > 0, 1, -1)\n",
    "predictions = np.ones(len(samples))\n",
    "\n",
    "misclassification_error = actual_classification != predictions\n",
    "\n",
    "hinge_loss = np.maximum(0, 1-(samples*predictions))\n",
    "\n",
    "criteria = samples*predictions\n",
    "\n",
    "hh_loss = np.where( criteria > (1+h), 0, np.where(criteria < (1 - h), 1 - criteria, ((1 +  h - criteria)**2)/(4*h)))\n",
    "\n",
    "plt.plot(samples, hinge_loss, color='blue', label='Hinge')\n",
    "plt.plot(samples, misclassification_error, color='black', label='Mis-class')\n",
    "plt.plot(samples, hh_loss, color='green', label='Huber-hinge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation between huber-hinge, hinge and misclassification loss functions\n",
    "\n",
    "The condition $ | 1 - yt | \\le h $ in huber-hinge loss function determines the spread which has to be smoothened by the loss function ($ \\frac{(1 + h - yt)^{2}}{4h} $) which is similar to squared loss function in the region determined by the value of h.\n",
    "\n",
    "### The parameter h\n",
    "As the value of h increases so does the spread of the smoothened curve.\n",
    "\n",
    "### Differentiablity, convexity and smoothness\n",
    "The huberized hinge loss gives a smooth, convex and differentiable upper bound for the misclassification error.  Whereas the hinge-loss gives a convex upper bound for the misclassification error.\n",
    "\n",
    "### Upper bounds\n",
    "The advantage of huberized hinge loss over other differentiable loss functions such as square loss is that we have a much tighter upper bound for huberized hinge loss than the squared loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of differentiability of huber-hinge loss function\n",
    "\n",
    "The huber hinge loss function is given by \n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "    l_{huber-hinge}(y,t) := & \n",
    "        \\begin{cases}\n",
    "            0 & \\text{if } yt \\gt 1 + h\\\\\n",
    "            \\frac{(1+h-yt)^{2}}{4h} & \\text{if } | 1 - yt | \\leq h\\\\\n",
    "            1 - yt & \\text{if } yt \\le 1 - h\n",
    "        \\end{cases}\n",
    "\\end{align} \n",
    "$\n",
    "\n",
    "By rewriting the rhs for each cases in the above piecewise equation, we get the limits as \n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "    l_{huber-hinge}(y,t) := & \n",
    "        \\begin{cases}\n",
    "            0 & \\text{if } y \\gt \\frac{1 + h}{t}\\\\\n",
    "            \\frac{(1+h-yt)^{2}}{4h} & \\text{if } \\frac{1-h}{t} \\leq y \\leq \\frac{1+h}{t} \\\\\n",
    "            1 - yt & \\text{if } y \\le \\frac{1 - h}{t}\n",
    "        \\end{cases}\n",
    "\\end{align} \n",
    "$\n",
    "\n",
    "For proving that the function is differentiable, we should show that the function is differentiable in all the three pieces.\n",
    "\n",
    "The derivative for the function when $ y \\gt \\frac{1+h}{t} $ is clearly defined and has the value of zero.\n",
    "\n",
    "The derivative for the function when $ y \\le \\frac{1-h}{t} $ is clearly defined and has the value of -t.\n",
    "\n",
    "The derivative for the function when $ \\frac{1-h}{t} \\leq y \\leq \\frac{1+h}{t} $ is clearly defined and has the value of $ \\frac{-t(1+h-yt)}{2h} $ (easily diffentiable by chain rule)\n",
    "\n",
    "We need to show that the function is differentiable at points $ \\frac{1-h}{t} $ and $ \\frac{1+h}{t} $\n",
    "\n",
    "As $ y \\to \\frac{1-h}{t} $, the left side limit is given by the function 1 - yt.  When y = $\\frac{1-h}{t}$, the left side derivative is h.  The right side derivative is given by $\\frac{(1+h-yt)^{2}}{4h} $ which again gives the value of h.  So the function is differntiable at $ \\frac{1-h}{t} $.\n",
    "\n",
    "Similary, we can show that the function is differentiable at $ \\frac{1+h}{t} $ as both the left side and right side limit will give the value of zero.\n",
    "\n",
    "Since the piecewise function $ f(y,t) $ is differentiable at all the points, the function is differentiable as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytic expression of gradient\n",
    "\n",
    "The analytic expression of gradient is given by$\n",
    "\\begin{align}\n",
    "    l_{huber-hinge}(y,t) := & \n",
    "        \\begin{cases}\n",
    "            0 & \\text{if } yt \\gt 1 + h\\\\\n",
    "            \\frac{-t(1+h-yt)}{2h} & \\text{if } | 1 - yt | \\leq h\\\\\n",
    "            -t & \\text{if } yt \\le 1 - h\n",
    "        \\end{cases}\n",
    "\\end{align} \n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  Lipschitz continuousness of Huberized Loss function\n",
    "\n",
    "We know that Huberized hinge loss is continuous as it is a differentiable function.  A function is Lipschitz continuous if it satisfies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
